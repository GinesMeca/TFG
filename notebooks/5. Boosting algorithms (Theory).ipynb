{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Boosting algortihms (Theory)\n",
    "\n",
    "This notebook will resume theorical concepts about boosting algorithms and it will show some useful plots and graphs for an easily understanding.\n",
    "\n",
    "### Index:\n",
    "1. [Introduction](#1.-Introduction)\n",
    "2. [AdaBoost](#2.-AdaBoost)\n",
    "3. [Gradient Boosting](#3.-Gradient-Boosting)\n",
    "4. [XGBoost](#4.-XGBoost)\n",
    "5. [LightGBM](#5.-LightGBM)\n",
    "6. [CatBoost](#6.-CatBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting algorithms were created in 1997 with the emergence of AdaBoost (by Freund & Schapire). They work building some weak learners (simple models) and ensembling them, creating a complex model. Also, these weak learners, in our case decision trees, are built sequentially; so, every decision tree (except the first) is allowed to correct the errors made by the last one. It's possible taking into account the weight of each sample and modifying it in each step.\n",
    "\n",
    "There are some boosting algorithms and some versions of each one. We will study: AdaBoost, Gradient Boosting, XGBoost, LightGBM and CatBoost.\n",
    "\n",
    "We also show some examples. That's the reason why we will need these python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load packages required:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost was the first boosting algorithm created. It uses stumps as a weak learners, i.e., decision trees with only two leaf nodes. These weak learners are very imprecise, but the combination of them and the way of building them results in a very attractive method.\n",
    "\n",
    "The AdaBoot algorithm we will analyze is:\n",
    "\n",
    "<img src=https://i.stack.imgur.com/ljZmk.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we assign the same weight for all samples, because we haven't done any prediction yet. So:\n",
    "\n",
    "\\begin{equation}\n",
    "w_i = 1/N \\, \\, \\, \\forall i \\in \\{ 1, 2, \\dots, N \\}\n",
    "\\end{equation}\n",
    "\n",
    "Then, we fit our stump ($G_m(x)$) using the weighted training data (if m = 1, we fit it like always), and we calculate the error made by the stump with:\n",
    "\n",
    "\\begin{equation}\n",
    "err_m = \\frac{\\sum_{i=1}^{N} w_i I(y_i \\neq G_m(x_i))}{\\sum_{i=1}^{N} w_i}\n",
    "\\end{equation}\n",
    "\n",
    "In this expression we have the sum of weights from incorrect classified values divided by the sum of total weights. The denominator is necessary in the expression because we can find a case where $\\sum_{i=1}^{N} w_i \\neq 1$ due to posterior modifications. So, if we define $err_m$ as we say, we can be sure of: $err_m \\in [0, 1]$.\n",
    "\n",
    "Note that in first step ( m = 1 ):\n",
    "\n",
    "\\begin{equation}\n",
    "err_1 = \\frac{\\sum_{i=1}^{N} w_i I(y_i \\neq G_1(x_i))}{\\sum_{i=1}^{N} w_i} = \\frac{\\frac{1}{N} \\sum_{i=1}^{N}I(y_i \\neq G_1(x_i))}{1} = \\frac{num\\_of\\_errors}{N}\n",
    "\\end{equation}\n",
    "\n",
    "Now, in 3c, we can observe that we have to define:\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_m = \\log \\left( \\frac{1 - err_m}{err_m} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "This value is also called: 'Amount of Say' for the stump. Let's plot this function to get conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-068c4c148198>:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  alpha = lambda x: np.log((1- x)/x)\n",
      "<ipython-input-3-068c4c148198>:6: RuntimeWarning: divide by zero encountered in log\n",
      "  alpha = lambda x: np.log((1- x)/x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We define our function:\n",
    "alpha = lambda x: np.log((1- x)/x)\n",
    "\n",
    "#We plot it:\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "plt.plot(x, alpha(x))\n",
    "plt.xlabel(r'$err_m$')\n",
    "plt.ylabel(r'$\\alpha_m$')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a good classification job ($err_m \\simeq 0$) implies high $\\alpha_m$ values. On the other hand, a poor classification job implies high negative values of $\\alpha_m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ending with the loop, we only have to reassign weights to training observations. The process to do it is defining:\n",
    "\\begin{equation*}\n",
    "w_i^{m+1} =\n",
    "\\left\\{\n",
    "\\begin{array}{crl}\n",
    "w_i^m & si & y_i = G_m(x_i) \\\\\n",
    "w_i^m e^{\\alpha_m} & si & y_i \\neq G_m(x_i) \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{equation*}\n",
    "where $w_i^m$ is the weight of the observation i in the iteration m.\n",
    "\n",
    "With this reassignment we obtain an increasement of weights of misclassified observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with the last step, we have to emphasize the way of building stumps. Where m = 1, we use the Gini index as a impurity function:\n",
    "\\begin{equation*}\n",
    "G_{region} = \\sum_{k=1}^K p_{rk}(1 - p_{rk}) = 1 - \\sum_{k=1}^K p_{rk}^2\n",
    "\\end{equation*}\n",
    "where $p_{rk}$ is the proportion of training observations from class k that are in region r; and K is the total number of classes. In the same way, each node determines two regions; so we can define:\n",
    "\\begin{equation*}\n",
    "G_{node} = \\frac{n_1}{n_1 + n_2}G_1 + \\frac{n_2}{n_1 + n_2}G_2\n",
    "\\end{equation*}\n",
    "where $n_1$ and $n_2$ are the number of observations in each region, respectively. That allows us to determinate which is the region that minimizes Gini index and to choose the correct variable and the value that make this regions.\n",
    "\n",
    "Nevertheless, this Gini index is only correct where all observations have the same weight. So, where m > 1, we need to define a weighted Gini index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Example step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To end with AdaBoost algorithm, we will show, step by step, which is the process with an example. We will use the dataset 'Rain in Australia' like in the other notebooks but choosing only the 5 first observations and the variables: 'Humidity3pm' and 'Cloud3pm'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Cloud3pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Humidity3pm  Cloud3pm\n",
       "0         22.0      -1.0\n",
       "1         25.0      -1.0\n",
       "2         30.0       2.0\n",
       "3         16.0      -1.0\n",
       "4         33.0       8.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We load data:\n",
    "weather = pd.read_parquet('../data/04_model_input/master.parquet')\n",
    "\n",
    "#We choose the variables and observations we are interested in:\n",
    "observations = [0, 1, 2, 3, 4]\n",
    "model_columns = ['Humidity3pm', 'Cloud3pm']\n",
    "\n",
    "#We put it in train variable and solve Nan problems\n",
    "train = weather.loc[observations, model_columns].fillna(-1)\n",
    "\n",
    "#We show it:\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
